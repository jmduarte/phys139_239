{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1, Parts C-E: Stochastic Gradient Descent Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we visualize how SGD works. \n",
    "This visualization corresponds to parts C-E of question 1 in homework 2.\n",
    "\n",
    "Use this notebook to write your code for problem 1 parts C-E by filling in the sections marked `# TODO` and running all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "from sgd_helper import (\n",
    "    generate_dataset1,\n",
    "    generate_dataset2,\n",
    "    plot_dataset,\n",
    "    plot_loss_function,\n",
    "    animate_convergence,\n",
    "    animate_sgd_suite,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1C: Implementation of SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the loss, gradient, and SGD functions according to the guidelines given in the problem statement in order to perform SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(X, Y, w):\n",
    "    \"\"\"\n",
    "    Calculate the squared loss function.\n",
    "\n",
    "    Inputs:\n",
    "        X: A (N, D) shaped numpy array containing the data points.\n",
    "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "        w: A (D, ) shaped numpy array containing the weight vector.\n",
    "\n",
    "    Outputs:\n",
    "        The loss evaluated with respect to X, Y, and w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ==============================================\n",
    "    # TODO: Implement the SGD loss function.\n",
    "    # ==============================================\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def gradient(x, y, w):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the loss function with respect to\n",
    "    a single point (x, y), and using weight vector w.\n",
    "\n",
    "    Inputs:\n",
    "        x: A (D, ) shaped numpy array containing a single data point.\n",
    "        y: The float label for the data point.\n",
    "        w: A (D, ) shaped numpy array containing the weight vector.\n",
    "\n",
    "    Output:\n",
    "        The gradient of the loss with respect to x, y, and w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ==============================================\n",
    "    # TODO: Implement the gradient of the\n",
    "    # loss function.\n",
    "    # ==============================================\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def SGD(X, Y, w_start, eta, N_epochs):\n",
    "    \"\"\"\n",
    "    Perform SGD using dataset (X, Y), initial weight vector w_start,\n",
    "    learning rate eta, and N_epochs epochs.\n",
    "\n",
    "    Inputs:\n",
    "        X: A (N, D) shaped numpy array containing the data points.\n",
    "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "        w_start:  A (D, ) shaped numpy array containing the weight vector initialization.\n",
    "        eta: The step size.\n",
    "        N_epochs: The number of epochs (iterations) to run SGD.\n",
    "\n",
    "    Outputs:\n",
    "        W: A (N_epochs, D) shaped array containing the weight vectors from all iterations.\n",
    "        losses: A (N_epochs, ) shaped array containing the losses from all iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    # ==============================================\n",
    "    # TODO: Implement the SGD algorithm.\n",
    "    # ==============================================\n",
    "\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1D: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start off by generating two simple 2-dimensional datasets. \n",
    "For simplicity, we do not consider separate training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X1, Y1 = generate_dataset1()\n",
    "plot_dataset(X1, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X2, Y2 = generate_dataset2()\n",
    "plot_dataset(X2, Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD from a single point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's visualize SGD from a single starting point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "# <FR> changes the animation speed.\n",
    "params = ({\"w_start\": [0.01, 0.01], \"eta\": 0.00001},)\n",
    "N_epochs = 1000\n",
    "FR = 20\n",
    "\n",
    "# Let's animate it!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR)\n",
    "anim.save(\"animation1.gif\", fps=30, writer=\"imagemagick\")\n",
    "Image(open(\"animation1.gif\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view how the weights change as the algorithm converges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "params = ({\"w_start\": [0.01, 0.01], \"eta\": 0.00001},)\n",
    "N_epochs = 1000\n",
    "FR = 20\n",
    "\n",
    "# Let's do it!\n",
    "W, _ = SGD(X1, Y1, params[0][\"w_start\"], params[0][\"eta\"], N_epochs)\n",
    "anim = animate_convergence(X1, Y1, W, FR)\n",
    "anim.save(\"animation2.gif\", fps=30, writer=\"imagemagick\")\n",
    "Image(open(\"animation2.gif\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD from multiple points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize SGD from multiple arbitrary starting points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "# Here, we specify each different set of initializations as a dictionary.\n",
    "params = (\n",
    "    {\"w_start\": [-0.8, -0.3], \"eta\": 0.00001},\n",
    "    {\"w_start\": [-0.9, 0.4], \"eta\": 0.00001},\n",
    "    {\"w_start\": [-0.4, 0.9], \"eta\": 0.00001},\n",
    "    {\"w_start\": [0.8, 0.8], \"eta\": 0.00001},\n",
    ")\n",
    "N_epochs = 1000\n",
    "FR = 20\n",
    "\n",
    "# Let's go!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR)\n",
    "anim.save(\"animation3.gif\", fps=30, writer=\"imagemagick\")\n",
    "Image(open(\"animation3.gif\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same thing but with a different dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "params = (\n",
    "    {\"w_start\": [-0.8, -0.3], \"eta\": 0.00001},\n",
    "    {\"w_start\": [-0.9, 0.4], \"eta\": 0.00001},\n",
    "    {\"w_start\": [-0.4, 0.9], \"eta\": 0.00001},\n",
    "    {\"w_start\": [0.8, 0.8], \"eta\": 0.00001},\n",
    ")\n",
    "N_epochs = 1000\n",
    "FR = 20\n",
    "\n",
    "# Animate!\n",
    "anim = animate_sgd_suite(SGD, loss, X2, Y2, params, N_epochs, FR)\n",
    "anim.save(\"animation4.gif\", fps=30, writer=\"imagemagick\")\n",
    "Image(open(\"animation4.gif\", \"rb\").read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1E: SGD with different step sizes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize SGD with different step sizes (eta):\n",
    "\n",
    "(For ease of visualization: the trajectories are ordered from left to right by increasing eta value. Also, note that we use smaller values of `N_epochs` and `FR` here for easier visualization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "params = (\n",
    "    {\"w_start\": [0.7, 0.8], \"eta\": 0.00001},\n",
    "    {\"w_start\": [0.2, 0.8], \"eta\": 0.00005},\n",
    "    {\"w_start\": [-0.2, 0.7], \"eta\": 0.0001},\n",
    "    {\"w_start\": [-0.6, 0.6], \"eta\": 0.0002},\n",
    ")\n",
    "N_epochs = 100\n",
    "FR = 2\n",
    "\n",
    "# Go!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR, ms=2)\n",
    "anim.save(\"animation5.gif\", fps=30, writer=\"imagemagick\")\n",
    "Image(open(\"animation5.gif\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting SGD Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the difference in convergence rates a different way. Plot the loss with respect to epoch (iteration) number for each value of eta on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plotting SGD convergence\"\"\"\n",
    "\n",
    "# ==============================================\n",
    "# TODO: For the given learning rates, plot the\n",
    "# loss for each epoch.\n",
    "# ==============================================\n",
    "\n",
    "eta_vals = [1e-6, 5e-6, 1e-5, 3e-5, 1e-4]\n",
    "w_start = [0.01, 0.01]\n",
    "N_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, a big step size results in fast convergence! Why don't we just set eta to a really big value, then? Say, eta=1?\n",
    "\n",
    "(Again, note that the FR is lower for this animation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "params = ({\"w_start\": [0.01, 0.01], \"eta\": 1},)\n",
    "N_epochs = 100\n",
    "FR = 2\n",
    "\n",
    "# Voila!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR, ms=2)\n",
    "anim.save(\"animation6.gif\", fps=30, writer=\"imagemagick\")\n",
    "Image(open(\"animation6.gif\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's try eta=10 as well. What happens? (Hint: look at W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "w_start = [0.01, 0.01]\n",
    "eta = 10\n",
    "N_epochs = 100\n",
    "\n",
    "# Presto!\n",
    "W, losses = SGD(X1, Y1, w_start, eta, N_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Visualization (not part of the homework problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final visualization! What happens if the loss function has multiple optima?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import different SGD & loss functions.\n",
    "# In particular, the loss function has multiple optima.\n",
    "from sgd_multiopt_helper import SGD, loss\n",
    "\n",
    "# Parameters to feed the SGD.\n",
    "params = (\n",
    "    {\"w_start\": [0.9, 0.9], \"eta\": 0.01},\n",
    "    {\"w_start\": [0.0, 0.0], \"eta\": 0.01},\n",
    "    {\"w_start\": [-0.8, 0.6], \"eta\": 0.01},\n",
    "    {\"w_start\": [-0.8, -0.6], \"eta\": 0.01},\n",
    "    {\"w_start\": [-0.4, -0.3], \"eta\": 0.01},\n",
    ")\n",
    "N_epochs = 100\n",
    "FR = 2\n",
    "\n",
    "# One more time!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR, ms=2)\n",
    "anim.save(\"animation7.gif\", fps=30, writer=\"imagemagick\")\n",
    "Image(open(\"animation7.gif\", \"rb\").read())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "phys139",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0ea348b636367bcdf67fd2d6d24251712b38670f61fdee14f28eb58fe74f081"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
